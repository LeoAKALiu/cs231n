{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture1.introduction\n",
    "> [这里是讲义](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture1.pdf)\n",
    "\n",
    "图像被称作互联网的“暗物质”  \n",
    "David Marr，1970s，stages of Visual Representation  \n",
    "1. input image\n",
    "2. primal sketch(edge image)\n",
    "3. 2 1/2-D sketch \n",
    "4. 3-D model  \n",
    "\n",
    "Face Detection,2001  \n",
    "Histogam of Gradients(HoG),Dalal & Triggs,2005  \n",
    "PASCAL Visual Object Challenge(20 object categories)  \n",
    "\n",
    "_现代图像识别问题是特征多，维度高，用算法经常过拟合_  \n",
    "\n",
    "*Image Net Challenge所用算法演变*  \n",
    "- Lin CVPR 2011---svm  \n",
    "- Krizhevsky NIPS 2012------cNN,Supervision(AlexNet)  \n",
    "- Szegedy arxiv 2014/Simonyan arxiv 2014-------VGG GoogleNet  \n",
    "- Microsoft Research Asia 2015-----152 layer Residual Networks  \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture2.image classificatioon\n",
    ">[这里是讲义](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture2.pdf)\n",
    "\n",
    "## Data-Driven Approach\n",
    "1. collect a dataset of images and labels\n",
    "2. use machine learning to train a classifier\n",
    "3. evaluate the classifier on new images  \n",
    "\n",
    "## 机器学习方法用于预测分类，一般分两个函数（步骤）：\n",
    "1. 输入函数→train\n",
    "2. 输出函数→predict  \n",
    "\n",
    "## 常用分类器1：Nearest Neighbor\n",
    "1. memorize all data and labels\n",
    "2. predict the label of the most similar train image  \n",
    "\n",
    "*Distance Metric to compare images*  \n",
    "L1 distance(Manhattan distance):$$d_1(I_1,I_2)=\\sum_{P}\\left | I_1^P - I_2^P \\right |$$  \n",
    "\n",
    "训练时间复杂度O(1), 预测时间复杂度O(N)，但是我们的需求是，训练时间可以长，但是预测速度越快越好  \n",
    "_缺点_：不准确,噪声点误分类  \n",
    "_改进_：K-Nearest Neighbor，给定一个K，将最邻近的K个样本点的分类作为最终预测结果\n",
    "\n",
    "*用欧几里得距离作为Distance Meric*  \n",
    "L2(Euclidean)distance:$$d_2(I_1,I_2)= \\sqrt{\\sum_{P}(I_1^P - I_2^P)^{2}}$$  \n",
    "### L1与L2区别 \n",
    "L1依赖于所选择的坐标系，若旋转坐标系，L1距离会变化  \n",
    "L2不依赖于坐标系  \n",
    "如果输入特征有特别含义，则用L1较好，如果特征间无差别，则用L2较好 \n",
    "\n",
    "### 设置K近邻的超参数  \n",
    "1. ×选择最佳超参数K（BAD：K=1总是对训练集拟合最好）\n",
    "2. ×分为训练集和测试集（BAD：只在测试集上预测效果好，不知道未知数据预测效果如何）  \n",
    "3. √分为训练集、验证集和测试集\n",
    "4. √cross-validation（在小数据集中非常有用，但在deep learning中不常用）\n",
    "\n",
    "_K-Nearest Neighbor on images **never used**_\n",
    "- Very slow at test time\n",
    "- Distance metrics on pixels are not informative\n",
    "L2距离对样本数据变化（图像变化，如遮挡，变换）不敏感\n",
    "- curse of dimensionality\n",
    "随着维度增加，数据个数（采样点）指数级增多  \n",
    "\n",
    "### summary\n",
    "- In image classification we start with a training set of images and labels , andd must predict labels on the test set \n",
    "- The K-Neatest Neighbors classifier predicts labels based on nearest training examples\n",
    "- Distance metric and K are hyperparameters\n",
    "- Choose hyperparameters using the validation set; only run on the test set once at the very end!  \n",
    "\n",
    "## 常用分类器2：线性分类\n",
    "### Parametric Approach\n",
    "一个尺寸为32（pixels）×32（pixels）×3（RGB）的图片，转为含3072数字的Array，通过权重矩阵W，转换为10个给定分类的分值  \n",
    "$$f(x) = Wx + b$$\n",
    "\n",
    "*不需要测试集*\n",
    "\n",
    "该方法试图在高维空间用线性划分分类,但对线性不可分集无用  \n",
    "\n",
    "如何用cost function评价W的好坏，下节课讲  \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture3.Loss Functions and Optimization\n",
    "\n",
    ">[这里是讲义](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture3.pdf)\n",
    "\n",
    "## 评价权重矩阵W的方法\n",
    "1. 定义一个loss function量化分类的好坏\n",
    "2. 找出最小化以上函数的参数（optimization）  \n",
    "\n",
    "## Loss function\n",
    "### 一般表示：  \n",
    "假设数据集的样本表示为$\\left\\{(x_i,y_i)\\right\\}^{N}_{i=1}$  \n",
    "$x_i$为图像，$y_i$为label（int）  \n",
    "数据集的损失表示为：$$L = \\frac{1}{N} \\sum_{i} L_i(f(x_i,W),y_i)$$  \n",
    "\n",
    "### Multiclass SVM loss(Hinge Loss)：  \n",
    "$$L_i = \\sum_{j\\neq y_i}\\max\\left ( 0,s_j - s_{y_i} + 1 \\right )$$\n",
    "其中：$s=f(x_i,W)$($s_j$表示预测分类分数，$s_{y_i}$表示其他分类分数)  \n",
    "$so:$  \n",
    "$$L = \\frac{1}{N} \\sum_{i=1}^{N} L_i$$\n",
    "几点特性：  \n",
    "- Hinge损失不关心具体数值，只关心不同值之间的大小关系\n",
    "- Hinge损失的取值范围为$[0,-\\infty)$\n",
    "- 若初始权重矩阵得出的s≈0，去掉一个分类重新赋值计算\n",
    "- 若想降低算法对误分类的容忍度，可用平方hinge损失  \n",
    "\n",
    "#### Hinge损失函数代码\n",
    "```python\n",
    "def L_i_wectorized(x, y, W):\n",
    "    scores = W.dot(x)\n",
    "    margins = np.maximum(0, scores - score[y] + 1)\n",
    "    margins[y] = 0\n",
    "    loss_i = np.sum(margins)\n",
    "    return loss_i\n",
    "```\n",
    "margins[y] = 0可保证迭代时跳过待计算分类（$s_j$），实现$j\\neq y_i$  \n",
    "\n",
    "### 正则项\n",
    "$$L = \\frac{1}{N} \\sum_{i=1}^{N}\\sum_{j\\neq y_i} \\max(0,f(x_i;W)_j - f(x_i;W)_{y_i} +1)+\\lambda R(W)$$  \n",
    "#### 常用正则项\n",
    "- L2 regularization $R(W)=\\sum_k \\sum_l W_{k,l}^2$ \n",
    "- L1 regularization $R(W)=\\sum_k \\sum_l \\left|W_{k,l}\\right|$\n",
    "- Elastic net(L1+L2) $R(W)=\\sum_k \\sum_l \\beta W_{k,l}^2 +\\left|W_{k,l}\\right|$\n",
    "- Max norm regularization\n",
    "- Dropout\n",
    "- Batch normalization\n",
    "- stochastic depth  \n",
    "\n",
    "### Softmax Classifier(Multinomial Logistic Regression)\n",
    "Softmax函数实际为normalize化的指数函数，即$softmax(x)=normalize(e^x)$  \n",
    "分类器损失函数如下：  \n",
    "$$P(Y=k|X=x_i)=\\frac{e^{s_k}}{\\sum_j e^{s_j}}\\quad\\text{其中}s=f(x_i;W)$$\n",
    "$$L_i=-logP(Y=y_i|X=x_i)$$\n",
    "$$so:L_i=-log(\\frac{e^{s_{y_i}}}{\\sum_j e^{s_j}})$$\n",
    "\n",
    "## Optimization\n",
    "### Follow the slope\n",
    "- In 1-dimension,the slope is the derivative of a function\n",
    "- In multiple dimensions, the slope is the gradient  \n",
    "\n",
    "### Analytic Gradient\n",
    "fast,efficient,but error-pron,could be debugging through numerical gradient（which is slow, approximat, easy to write）  \n",
    "### Gradient Descent\n",
    "```python\n",
    "while True:\n",
    "    weights_grad = evaluate_gradient(loss_fun, data, weights)\n",
    "    weights += - step_size * weights_grad # perform parameter update\n",
    "```\n",
    "### Stochastic Gradient Descent(SGD)\n",
    "Full sum expensive when N is large  \n",
    "Approximate sum using a **minibatch** of examples(32/64/128 common size)   \n",
    "```python\n",
    "while True:\n",
    "    data_batch = sample_training_data(data, 256) # sample 256 examples\n",
    "    weights_grad = evaluate_gradient(loss_fun, data_batch, weights)\n",
    "    weights += - step_size * weights_grad # perform parameter update  \n",
    "```\n",
    "### Linear Classification Loss Visualization\n",
    "用动画显示训练过程，可调超参数，观察收敛速度和方式\n",
    "[链接](http://vision.stanford.edu/teaching/cs231n-demos/linear-classify/)  \n",
    "### 对于图片特征线性不可分\n",
    "可采用以下方法进行特征变换：\n",
    "1. Color Histogram  \n",
    "把每个色彩的pixel数累计在相应的color bar下  \n",
    "2. Histogram of Oriented Gradients(HoG)  \n",
    "3. Bag of Words  \n",
    " - Step1.Build codebook\n",
    " - Step2.Encode images  \n",
    " ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture4.Introduction to Neural Networks\n",
    ">[这里是讲义](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture4.pdf)\n",
    "\n",
    "## BP算法相关\n",
    "### Chain rule\n",
    "Backpropagation中的重要方法，利用chain rule由输出节点反向计算输入节点的梯度。  \n",
    "假设三层神经网络（一输入层，两隐藏层），输入矩阵为$X = [x_1,x_2,...,x_m]$，分别经过Hidden layer1（权重矩阵$\\theta_1$，激活函数$f(z)$）,Hidden layer2（权重矩阵$\\theta_2$，激活函数$g(z)$），到达输出层（权重矩阵$\\theta_3$，激活函数$h(z)$），输出向量为$y = [y_1,y_2,...,y_n]。  \n",
    "\n",
    "即：  \n",
    "\n",
    "$$Z^{(1)} = \\theta_1\\cdot X$$  \n",
    "\n",
    "$$Z^{(2)} = \\theta_2\\cdot f(Z^{(1)})$$  \n",
    "\n",
    "$$Z^{(3)} = \\theta_3\\cdot g(Z^{(2)})$$  \n",
    "\n",
    "$$y = h(Z^{(3)})$$\n",
    "\n",
    "\n",
    "那么，在算得输出节点损失$\\delta $后，可根据chain rule反向传播到Hidden layer2的损失如下：  \n",
    "\n",
    "$$\\frac{\\partial y}{\\partial Z_2} = $$\n",
    "\n",
    "\n",
    "### forward\n",
    "由输入向前计算得到输出，保存中间变量（$Z^{(i)}$）\n",
    "### backward\n",
    "应用chain rule及中间变量，计算各步关于输入量的损失\n",
    "\n",
    "## Neural Network\n",
    "### 几种激活函数\n",
    "- Sigmoid  \n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$\n",
    "- tanh $$tanh(x)$$\n",
    "- ReLU (Rectified Linear Units)[Yann LeCun,2009](http://yann.lecun.com/exdb/publis/pdf/jarrett-iccv-09.pdf) $$\\max(0,x)$$\n",
    "- Leaky ReLU $$\\max(0.1x,x)$$\n",
    "- ELU  \n",
    "$$\\left\\{\n",
    "\\begin{aligned}\n",
    "x\\quad x\\geqslant 0 \\\\\n",
    "\\alpha (e^{x} -1)\\quad x<0\n",
    "\\end{aligned}\n",
    "\\right.$$  \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture5.Convolutional Neural Networks\n",
    ">[这里是讲义](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture5.pdf)  \n",
    "\n",
    "## History\n",
    "- Frank Rosenblatt, 1957, Perceptron\n",
    "- Widrow and Hoff, 1960, Adaline/Madaline\n",
    "- Rumelhar,1986, First time back-propagation became popular\n",
    "- Hinton and Salakhutdinov, 2006, [Reinvigorated research in Deep Learning](https://www.cs.toronto.edu/~hinton/science.pdf)\n",
    "- Hinton Krizhevsky and Sutskever, 2012, [First strong results:AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)  \n",
    "\n",
    "## today\n",
    "- Hinton, 2012, [Reproduced with permission](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)\n",
    "- Ren He and Girshick, 2015, [Faster R-CNN](https://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf)\n",
    "- Taigman, 2014, [face recognition](https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf)  \n",
    "\n",
    "## Convolution\n",
    "卷积的定义：[百度百科](https://baike.baidu.com/item/%E5%8D%B7%E7%A7%AF/9411006?fr=aladdin&fromid=18080681&fromtitle=Convolution)\n",
    "[wikipedia](https://en.wikipedia.org/wiki/Convolution)  \n",
    "filter 和 image的元素相乘求和：  \n",
    "$$f[x,y]*g[x,y] = \\sum_{n_1=-\\infty}^{\\infty}\\sum_{n_2=-\\infty}^{\\infty} f[n_1,n_2]\\cdot g[x-n_1,y-n_2]$$  \n",
    "\n",
    "## Filter and padding\n",
    "1. 用3×3的filter卷过7×7像素的图片  \n",
    "    - stride=1 得到一个5×5的output\n",
    "    - stride=2 得到一个3×3的output\n",
    "    - stride=3 不匹配！\n",
    "    - 一般说来，卷积层尺寸为（N-F）/stride+1\n",
    "2. 用3×3边缘用0填充的filter卷过7×7像素（边缘同样用0填充）的图片\n",
    "    - stride=1 得到一个7×7的output\n",
    "    - stride=3 得到一个3×3的output\n",
    "    - 若想得到同样尺寸的卷积层：\n",
    "        - filter尺寸为3×3时，需填充（zero pad）1行像素0\n",
    "        - filter尺寸为5×5时，zero pad with 2\n",
    "        - filter尺寸为7×7时，zero pad with 3  \n",
    "        - 一般说来zero pad with（F-1）/2即可得到同样尺寸的卷积层（F为filter尺寸）  \n",
    "        \n",
    "3. 1中的padding称为‘valid padding’，2中的padding称为‘same padding’（不会丢掉edge和Corner的信息）  \n",
    "\n",
    "## Pooling layer\n",
    "- makes the representations smaller and more manageable\n",
    "- operates over each activation map independently  \n",
    "\n",
    "### max polling  \n",
    "\n",
    "### summary\n",
    "- ConvNets 是卷积层（CONV），池化层（POOL），全链接层（FC）的堆叠\n",
    "- 倾向于用更小的filter和更深的结构\n",
    "- 倾向于用更多的卷积层、更少的池化层和全链接层\n",
    "- 典型结构：[(CONV-RELU)×N-POOL]×M-(FC-RELU)×K,SOFTMAX\n",
    "    - N一般5以内，M很大，K一般2以内  \n",
    "***    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture6.Training Neural Networks1\n",
    ">[这里是讲义](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture6.pdf)\n",
    "\n",
    "## Mini-batch SGD\n",
    "循环：\n",
    "- 随机取一部分（batch）样本\n",
    "- 前向传播得到损失\n",
    "- Backpropagation 计算梯度\n",
    "- 用梯度更新参数  \n",
    "\n",
    "## Activation Functions  \n",
    "\n",
    "常见激活函数：  \n",
    "\n",
    "### sigmoid\n",
    "- Squashes numbers to range[0,1]\n",
    "- 曾经最经典的激活函数，良好的解释性，有很好的性质（指数、导数），但不适用于Backpropagation  \n",
    "缺点：  \n",
    "- 使梯度‘消失’，Backpropagation中（梯度为$\\frac{\\partial{f}}{\\partial{x}}=sigmoid(1-sigmoid)$）：\n",
    "    - 当x为较小负数，梯度趋近于0\n",
    "    - 当x为0（附近）时，梯度可继续计算\n",
    "    - 当x为较大正数，梯度趋近于0  \n",
    "- Sigmoid的输出不是以0为中心\n",
    "    - 若输入为全正或全负，\n",
    "- 指数计算耗时长  \n",
    "\n",
    "### tanh(x)\n",
    "- Squashes numbers to range[-1,1]\n",
    "- 输出以0为中心（优于sigmoid）\n",
    "- 仍使梯度在较大正负值处消失  \n",
    "\n",
    "### ReLU\n",
    "- 在正数区域不会‘饱和’\n",
    "- 计算快\n",
    "- 收敛速度快于$tanh(x)$和$sigmoid$ （一般快6倍）  \n",
    "缺点：\n",
    "- 输出不以0为中心\n",
    "- 在负数区依然会饱和，且梯度为0\n",
    "- 当数据位于非激活区时（负数），该部分权重也得不到更新\n",
    "    - 解决办法：初始化ReLU时，加一个小的正偏置（bias，比如0.01）  \n",
    "    \n",
    "### Leaky ReLU\n",
    "- 不会‘饱和’\n",
    "- 计算快\n",
    "- 收敛速度快于$tanh(x)$和$sigmoid$ （一般快6倍）\n",
    "- 不存在像ReLU一样的缺点  \n",
    "- Parametric Rectifier(PReLU):$f(x)=\\max{(\\alpha x,x)}$  \n",
    "\n",
    "### ELU\n",
    "- 具有ReLU的优点\n",
    "- 输出均值接近0\n",
    "- 相比Leaky ReLU，负饱和区对噪声的鲁棒性更好  \n",
    "\n",
    "### Maxout 'Neuron'[Goodfellow,2013](http://proceedings.mlr.press/v28/goodfellow13.pdf)  \n",
    "\n",
    "### 建议\n",
    "- 首选ReLU，慎重选择学习率\n",
    "- 尝试Leaky ReLU、Maxout、ELU\n",
    "- 尝试tanh（可能并不会太好）\n",
    "- **不要用sigmoid！！！！！**  \n",
    "\n",
    "## Data Preprocessing\n",
    "### preprocess the data\n",
    "- zero-mean\n",
    "```python\n",
    "X -= np.mean(X, axis=0)\n",
    "```\n",
    "- normalized（机器学习中常用方法，但图像处理中一般不需要）\n",
    "```python\n",
    "X /= np.std(X, axis=0)\n",
    "```\n",
    "- PCA/Whitening 与normalized一样，不常用于图像处理  \n",
    "\n",
    "### 例子\n",
    "比如CIFAR-10中的32×32×3的图像，有以下两种处理方式：\n",
    "- 减去整个图像（所有样本）的平均（AlexNet）  \n",
    "（mean image是一个32×32×3的array）  \n",
    "- 减去每个通道的平均（VGGNet）  \n",
    "\n",
    "## Weight initialization\n",
    "- small random numbers（服从高斯分布，均值为0，方差为0.01）  \n",
    "```\n",
    "W = 0.01 * np.random.randn(D,H)\n",
    "```  \n",
    "    - 小型神经网络可以，深度网络不合适（方差衰减，所有值变为0）\n",
    "    - 一个比较好的方法[‘Xavier initialization’](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.207.2059&rep=rep1&type=pdf)\n",
    "    - 另一个方法[He et al. 2015](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n",
    "    \n",
    "## Batch Normalization\n",
    "步骤：  \n",
    "1. 在各维度上独立的求出均值和方差\n",
    "2. Normalize\n",
    "3. （一般）插入全链接层和卷积层之后\n",
    "优点：  \n",
    "- improve gradient flow through the network\n",
    "- 允许更高的学习率 \n",
    "- 降低对（权重？）初始化的依赖  \n",
    "注意：\n",
    "- 在测试集上不再重新计算mean\n",
    "\n",
    "## 训练模型中出现的几点问题\n",
    "1. loss不下降或下降很慢（但准确率在上升）\n",
    "    - 学习率太低。由于softmax选择最大值的特性，可能造成准确率上升而损失不下降的现象\n",
    "2. loss返回NaN（explode）\n",
    "    - 学习率太高\n",
    "3. 学习率一般取1e-3到1e-5  \n",
    "\n",
    "## Hyperparameter Optimization\n",
    "### Cross-validation\n",
    "1. 用较小的迭代次数粗略的选出大概合适的超参数范围\n",
    "2. 增多迭代次数，继续选出精确的超参数\n",
    "    - 如果cost一直大于3倍于初始cost，说明参数错误，尽早终止  \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lecture7.Training Neural Networks2\n",
    ">[这里是讲义]("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
